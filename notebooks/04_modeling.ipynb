{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74b732ee",
   "metadata": {},
   "source": [
    "Model Development, Tuning, and Ensemble Methods\n",
    "\n",
    "Notebook Purpose\n",
    "Build, tune, and combine machine learning models to predict Titanic survival.\n",
    "\n",
    "Input\n",
    "- `train_features.csv` - Training data with engineered features\n",
    "- `test_features.csv` - Test data with engineered features  \n",
    "- `test_passenger_ids.csv` - Passenger IDs for submission\n",
    "\n",
    "Output\n",
    "- Trained model files (`.pkl`)\n",
    "- Model comparison metrics and visualizations\n",
    "- Kaggle submission file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4939479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, cross_val_score, StratifiedKFold,\n",
    "    GridSearchCV, RandomizedSearchCV\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, GradientBoostingClassifier,\n",
    "    VotingClassifier, StackingClassifier\n",
    ")\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, roc_auc_score, roc_curve\n",
    ")\n",
    "from xgboost import XGBClassifier\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50929590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up visualization options\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7edd8c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c67f6ee",
   "metadata": {},
   "source": [
    "Load Feature-Engineered Data\n",
    "\n",
    "Loading from the previous checkpoint - our feature engineering outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b627df09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (891, 35)\n",
      "Test set: (418, 34)\n",
      "\n",
      "Training columns: ['Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Sex_encoded', 'Embarked_C', 'Embarked_Q', 'Embarked_S', 'Deck_A', 'Deck_B', 'Deck_C', 'Deck_D', 'Deck_E', 'Deck_F', 'Deck_G', 'Deck_T', 'Deck_Unknown', 'FamilySize', 'IsAlone', 'Title_Master', 'Title_Miss', 'Title_Mr', 'Title_Mrs', 'Title_Rare', 'Age_Child', 'Age_Teenager', 'Age_Young_Adult', 'Age_Adult', 'Age_Senior', 'Fare_Low', 'Fare_Medium', 'Fare_High', 'Fare_Very_High']\n"
     ]
    }
   ],
   "source": [
    "# Load the feature-engineered datasets\n",
    "train_df = pd.read_csv('../data/processed/train_features.csv')\n",
    "test_df = pd.read_csv('../data/processed/test_features.csv')\n",
    "test_ids = pd.read_csv('../data/processed/test_passenger_ids.csv')\n",
    "\n",
    "print(f\"Training set: {train_df.shape}\")\n",
    "print(f\"Test set: {test_df.shape}\")\n",
    "print(f\"\\nTraining columns: {train_df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93302828",
   "metadata": {},
   "source": [
    "Prepare Features and Target\n",
    "\n",
    "Why Separate X and y?\n",
    "Machine learning models expect:\n",
    "- **X** (features): The input variables used to make predictions\n",
    "- **y** (target): The outcome we're trying to predict (Survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93109e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (891, 34)\n",
      "Target shape: (891,)\n",
      "Target distribution:\n",
      "Survived\n",
      "0    0.616162\n",
      "1    0.383838\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target\n",
    "X = train_df.drop('Survived', axis=1)\n",
    "y = train_df['Survived']\n",
    "\n",
    "# Test set (no target - that's what we predict)\n",
    "X_test_final = test_df.copy()\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Target distribution:\\n{y.value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39564dae",
   "metadata": {},
   "source": [
    "Train-Validation Split\n",
    "\n",
    "Why Split the Training Data?\n",
    "We need to evaluate our model on data it hasn't seen during training. This gives us \n",
    "an honest estimate of how well it will perform on the actual test set.\n",
    "\n",
    "- **Training set (80%)**: Used to train the model\n",
    "- **Validation set (20%)**: Used to evaluate and compare models\n",
    "\n",
    "Stratified Splitting\n",
    "We use stratified splitting to ensure the same proportion of survivors in both \n",
    "train and validation sets. This is important because our classes are imbalanced (~38% survived)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fbe80774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (712, 34)\n",
      "Validation set: (179, 34)\n",
      "\n",
      "Training target distribution:\n",
      "Survived\n",
      "0    0.616573\n",
      "1    0.383427\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Validation target distribution:\n",
      "Survived\n",
      "0    0.614525\n",
      "1    0.385475\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Split into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y  # Maintain class proportions\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}\")\n",
    "print(f\"\\nTraining target distribution:\\n{y_train.value_counts(normalize=True)}\")\n",
    "print(f\"\\nValidation target distribution:\\n{y_val.value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705ede8b",
   "metadata": {},
   "source": [
    "Feature Scaling\n",
    "\n",
    "Why Scale Features?\n",
    "Some algorithms (like Logistic Regression) are sensitive to feature scales:\n",
    "- Age ranges from 0-80\n",
    "- Fare ranges from 0-512\n",
    "- Binary features are just 0 or 1\n",
    "\n",
    "**StandardScaler** transforms features to have mean=0 and std=1.\n",
    "\n",
    "Important: Fit on Training Only!\n",
    "We fit the scaler on training data and transform both train and validation. \n",
    "This prevents \"data leakage\" - using information from the validation set during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "864260e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature scaling complete!\n",
      "\n",
      "Scaled training data sample (first 3 rows, first 5 columns):\n",
      "       Pclass       Age     SibSp     Parch      Fare\n",
      "692  0.829568 -0.322182 -0.465084 -0.466183  0.513812\n",
      "481 -0.370945  0.053575 -0.465084 -0.466183 -0.662563\n",
      "527 -1.571457  0.805089 -0.465084 -0.466183  3.955399\n"
     ]
    }
   ],
   "source": [
    "# Initialize scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training data, transform both\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test_final)\n",
    "\n",
    "# Convert back to DataFrames for easier handling\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_val_scaled = pd.DataFrame(X_val_scaled, columns=X_val.columns, index=X_val.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test_final.columns)\n",
    "\n",
    "print(\"Feature scaling complete!\")\n",
    "print(f\"\\nScaled training data sample (first 3 rows, first 5 columns):\")\n",
    "print(X_train_scaled.iloc[:3, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39f8a85",
   "metadata": {},
   "source": [
    "Cross-Validation Setup\n",
    "\n",
    "Why Cross-Validation?\n",
    "A single train-validation split can give unstable results depending on which samples \n",
    "end up in which set. Cross-validation gives us a more reliable estimate by:\n",
    "\n",
    "1. Splitting data into K folds\n",
    "2. Training K times, each time using a different fold as validation\n",
    "3. Averaging the results\n",
    "\n",
    "We'll use **5-fold stratified cross-validation** for model comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "191ecd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# Helper function to evaluate models\n",
    "def evaluate_model(model, X_train, y_train, X_val, y_val, model_name):\n",
    "    \"\"\"\n",
    "    Train model and return comprehensive evaluation metrics.\n",
    "    \"\"\"\n",
    "    # Train\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred_proba = model.predict_proba(X_val)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy_score(y_val, y_pred),\n",
    "        'Precision': precision_score(y_val, y_pred),\n",
    "        'Recall': recall_score(y_val, y_pred),\n",
    "        'F1': f1_score(y_val, y_pred),\n",
    "        'ROC_AUC': roc_auc_score(y_val, y_pred_proba) if y_pred_proba is not None else None\n",
    "    }\n",
    "    \n",
    "    # Cross-validation score (on full training set)\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "    metrics['CV_Mean'] = cv_scores.mean()\n",
    "    metrics['CV_Std'] = cv_scores.std()\n",
    "    \n",
    "    return metrics, y_pred, y_pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cb3d6f",
   "metadata": {},
   "source": [
    "Model 1: Logistic Regression (Baseline)\n",
    "\n",
    "Why Start with Logistic Regression?\n",
    "Logistic Regression is the classic baseline for binary classification:\n",
    "- **Simple and interpretable**: Coefficients show feature importance\n",
    "- **Fast to train**: Works well even on larger datasets\n",
    "- **Sets a benchmark**: If complex models don't beat this, they're not worth the complexity\n",
    "\n",
    "How It Works\n",
    "Logistic regression models the probability of survival as:\n",
    "P(Survived=1) = 1 / (1 + e^-(β₀ + β₁x₁ + ... + βₙxₙ))\n",
    "\n",
    "Each coefficient (β) tells us how that feature affects survival odds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "84f227d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training baseline models...\n",
      "--------------------------------------------------\n",
      "Logistic Regression: 0.8132\n",
      "Random Forest:       0.8132\n",
      "XGBoost:             0.8132\n"
     ]
    }
   ],
   "source": [
    "print(\"Training baseline models...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "lr_base = LogisticRegression(random_state=RANDOM_STATE, max_iter=1000)\n",
    "lr_base_score = cross_val_score(lr_base, X_train_scaled, y_train, cv=cv).mean()\n",
    "print(f\"Logistic Regression: {lr_base_score:.4f}\")\n",
    "\n",
    "rf_base = RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE)\n",
    "rf_base_score = cross_val_score(rf_base, X_train, y_train, cv=cv).mean()\n",
    "print(f\"Random Forest:       {rf_base_score:.4f}\")\n",
    "\n",
    "xgb_base = XGBClassifier(random_state=RANDOM_STATE, eval_metric='logloss')\n",
    "xgb_base_score = cross_val_score(xgb_base, X_train, y_train, cv=cv).mean()\n",
    "print(f\"XGBoost:             {xgb_base_score:.4f}\")\n",
    "\n",
    "baseline = {'Logistic Regression': lr_base_score, \n",
    "            'Random Forest': rf_base_score, \n",
    "            'XGBoost': xgb_base_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f7065dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuning Logistic Regression...\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best CV: 0.8231 | Params: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTuning Logistic Regression...\")\n",
    "lr_grid = GridSearchCV(\n",
    "    LogisticRegression(random_state=RANDOM_STATE, max_iter=1000),\n",
    "    param_grid={\n",
    "        'C': [0.01, 0.1, 1, 10, 100],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear']\n",
    "    },\n",
    "    cv=cv, scoring='accuracy', n_jobs=-1, verbose=1\n",
    ")\n",
    "lr_grid.fit(X_train_scaled, y_train)\n",
    "lr_tuned = lr_grid.best_estimator_\n",
    "print(f\"Best CV: {lr_grid.best_score_:.4f} | Params: {lr_grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "686d9538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuning Random Forest...\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "Best CV: 0.8343 | Params: {'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 5}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTuning Random Forest...\")\n",
    "rf_search = RandomizedSearchCV(\n",
    "    RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "    param_distributions={\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [5, 10, 15, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'max_features': ['sqrt', 'log2']\n",
    "    },\n",
    "    n_iter=40, cv=cv, scoring='accuracy', n_jobs=-1, verbose=1, random_state=RANDOM_STATE\n",
    ")\n",
    "rf_search.fit(X_train, y_train)\n",
    "rf_tuned = rf_search.best_estimator_\n",
    "print(f\"Best CV: {rf_search.best_score_:.4f} | Params: {rf_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e23628b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuning XGBoost...\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "Best CV: 0.8371 | Params: {'subsample': 0.6, 'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.1, 'colsample_bytree': 0.8}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTuning XGBoost...\")\n",
    "xgb_search = RandomizedSearchCV(\n",
    "    XGBClassifier(random_state=RANDOM_STATE, eval_metric='logloss'),\n",
    "    param_distributions={\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "    },\n",
    "    n_iter=40, cv=cv, scoring='accuracy', n_jobs=-1, verbose=1, random_state=RANDOM_STATE\n",
    ")\n",
    "xgb_search.fit(X_train, y_train)\n",
    "xgb_tuned = xgb_search.best_estimator_\n",
    "print(f\"Best CV: {xgb_search.best_score_:.4f} | Params: {xgb_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "18688f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuning KNN...\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best CV: 0.8105\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTuning KNN...\")\n",
    "knn_grid = GridSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    param_grid={\n",
    "        'n_neighbors': [3, 5, 7, 9, 11],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['euclidean', 'manhattan']\n",
    "    },\n",
    "    cv=cv, scoring='accuracy', n_jobs=-1, verbose=1\n",
    ")\n",
    "knn_grid.fit(X_train_scaled, y_train)\n",
    "knn_tuned = knn_grid.best_estimator_\n",
    "print(f\"Best CV: {knn_grid.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "33dc198d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuning Gradient Boosting...\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best CV: 0.8329\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTuning Gradient Boosting...\")\n",
    "gb_search = RandomizedSearchCV(\n",
    "    GradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "    param_distributions={\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.05, 0.1, 0.2],\n",
    "        'min_samples_split': [2, 5]\n",
    "    },\n",
    "    n_iter=20, cv=cv, scoring='accuracy', n_jobs=-1, verbose=1, random_state=RANDOM_STATE\n",
    ")\n",
    "gb_search.fit(X_train, y_train)\n",
    "gb_tuned = gb_search.best_estimator_\n",
    "print(f\"Best CV: {gb_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3b05c77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "TUNED SINGLE MODELS\n",
      "==================================================\n",
      "XGBoost               : 0.8371 (+0.0239)\n",
      "Random Forest         : 0.8343 (+0.0211)\n",
      "Gradient Boosting     : 0.8329\n",
      "Logistic Regression   : 0.8231 (+0.0098)\n",
      "KNN                   : 0.8105\n"
     ]
    }
   ],
   "source": [
    "all_models = {\n",
    "    'Logistic Regression': (lr_tuned, lr_grid.best_score_, True),\n",
    "    'Random Forest': (rf_tuned, rf_search.best_score_, False),\n",
    "    'XGBoost': (xgb_tuned, xgb_search.best_score_, False),\n",
    "    'KNN': (knn_tuned, knn_grid.best_score_, True),\n",
    "    'Gradient Boosting': (gb_tuned, gb_search.best_score_, False)\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"TUNED SINGLE MODELS\")\n",
    "print(\"=\" * 50)\n",
    "for name, (_, score, _) in sorted(all_models.items(), key=lambda x: x[1][1], reverse=True):\n",
    "    base = baseline.get(name, None)\n",
    "    diff = f\" (+{score-base:.4f})\" if base else \"\"\n",
    "    print(f\"{name:22}: {score:.4f}{diff}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc0da8a",
   "metadata": {},
   "source": [
    "Ensemble Methods\n",
    "\n",
    "Voting Classifier\n",
    "- **Hard Voting**: Majority class wins\n",
    "- **Soft Voting**: Average probabilities, highest wins\n",
    "\n",
    "Stacking Classifier\n",
    "- Base models make predictions\n",
    "- Meta-model learns to combine them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "25347585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building Voting Ensembles...\n",
      "Hard Voting (3 trees):  0.8470\n",
      "Soft Voting (3 trees):  0.8442\n",
      "Soft Voting (5 models): 0.8343\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBuilding Voting Ensembles...\")\n",
    "\n",
    "# Hard voting (tree-based models)\n",
    "voting_hard = VotingClassifier(\n",
    "    estimators=[('rf', rf_tuned), ('xgb', xgb_tuned), ('gb', gb_tuned)],\n",
    "    voting='hard'\n",
    ")\n",
    "hard_score = cross_val_score(voting_hard, X_train, y_train, cv=cv).mean()\n",
    "print(f\"Hard Voting (3 trees):  {hard_score:.4f}\")\n",
    "\n",
    "# Soft voting (tree-based models)\n",
    "voting_soft = VotingClassifier(\n",
    "    estimators=[('rf', rf_tuned), ('xgb', xgb_tuned), ('gb', gb_tuned)],\n",
    "    voting='soft'\n",
    ")\n",
    "soft_score = cross_val_score(voting_soft, X_train, y_train, cv=cv).mean()\n",
    "print(f\"Soft Voting (3 trees):  {soft_score:.4f}\")\n",
    "\n",
    "# Mixed ensemble (5 models with pipelines for scaled models)\n",
    "voting_mixed = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', Pipeline([('scaler', StandardScaler()), ('lr', lr_tuned)])),\n",
    "        ('rf', rf_tuned),\n",
    "        ('xgb', xgb_tuned),\n",
    "        ('gb', gb_tuned)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "mixed_score = cross_val_score(voting_mixed, X_train, y_train, cv=cv).mean()\n",
    "print(f\"Soft Voting (5 models): {mixed_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "04d2c132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building Stacking Ensembles...\n",
      "Stacking:               0.8400\n",
      "Stacking + Passthrough: 0.8315\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBuilding Stacking Ensembles...\")\n",
    "\n",
    "# Basic stacking\n",
    "stacking = StackingClassifier(\n",
    "    estimators=[('rf', rf_tuned), ('xgb', xgb_tuned), ('gb', gb_tuned)],\n",
    "    final_estimator=LogisticRegression(random_state=RANDOM_STATE),\n",
    "    cv=5\n",
    ")\n",
    "stack_score = cross_val_score(stacking, X_train, y_train, cv=cv).mean()\n",
    "print(f\"Stacking:               {stack_score:.4f}\")\n",
    "\n",
    "# Stacking with passthrough (meta-learner sees original features too)\n",
    "stacking_pt = StackingClassifier(\n",
    "    estimators=[('rf', rf_tuned), ('xgb', xgb_tuned), ('gb', gb_tuned)],\n",
    "    final_estimator=LogisticRegression(random_state=RANDOM_STATE, max_iter=1000),\n",
    "    cv=5,\n",
    "    passthrough=True\n",
    ")\n",
    "stack_pt_score = cross_val_score(stacking_pt, X_train, y_train, cv=cv).mean()\n",
    "print(f\"Stacking + Passthrough: {stack_pt_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2ec8515f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_models = {\n",
    "    'Hard Voting (3)': (voting_hard, hard_score, False),\n",
    "    'Soft Voting (3)': (voting_soft, soft_score, False),\n",
    "    'Soft Voting (5)': (voting_mixed, mixed_score, False),\n",
    "    'Stacking': (stacking, stack_score, False),\n",
    "    'Stacking + Passthrough': (stacking_pt, stack_pt_score, False)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a597a9a3",
   "metadata": {},
   "source": [
    "Complete Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7d5a3a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ALL MODELS RANKED BY CV ACCURACY\n",
      "============================================================\n",
      "[E] Hard Voting (3)          : 0.8470\n",
      "[E] Soft Voting (3)          : 0.8442\n",
      "[E] Stacking                 : 0.8400\n",
      "[S] XGBoost                  : 0.8371\n",
      "[E] Soft Voting (5)          : 0.8343\n",
      "[S] Random Forest            : 0.8343\n",
      "[S] Gradient Boosting        : 0.8329\n",
      "[E] Stacking + Passthrough   : 0.8315\n",
      "[S] Logistic Regression      : 0.8231\n",
      "[S] KNN                      : 0.8105\n",
      "\n",
      "============================================================\n",
      "BEST MODEL: Hard Voting (3) (0.8470)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "all_results = {**all_models, **ensemble_models}\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ALL MODELS RANKED BY CV ACCURACY\")\n",
    "print(\"=\" * 60)\n",
    "for name, (_, score, _) in sorted(all_results.items(), key=lambda x: x[1][1], reverse=True):\n",
    "    tag = \"[E]\" if name in ensemble_models else \"[S]\"\n",
    "    print(f\"{tag} {name:25}: {score:.4f}\")\n",
    "\n",
    "best_name = max(all_results.items(), key=lambda x: x[1][1])[0]\n",
    "best_model, best_score, needs_scaling = all_results[best_name]\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"BEST MODEL: {best_name} ({best_score:.4f})\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5a7d2186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "names = list(all_results.keys())\n",
    "scores = [all_results[n][1] for n in names]\n",
    "colors = ['steelblue' if n in all_models else 'coral' for n in names]\n",
    "\n",
    "sorted_data = sorted(zip(names, scores, colors), key=lambda x: x[1], reverse=True)\n",
    "names, scores, colors = zip(*sorted_data)\n",
    "\n",
    "bars = ax.bar(names, scores, color=colors)\n",
    "ax.set_ylabel('CV Accuracy')\n",
    "ax.set_title('Model Comparison: Single [S] vs Ensemble [E]')\n",
    "ax.set_ylim(0.78, 0.88)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "ax.legend(handles=[\n",
    "    Patch(facecolor='steelblue', label='Single Model'),\n",
    "    Patch(facecolor='coral', label='Ensemble')\n",
    "], loc='upper right')\n",
    "\n",
    "for bar, score in zip(bars, scores):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.002,\n",
    "            f'{score:.4f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/model_comparison.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912e75ed",
   "metadata": {},
   "source": [
    "Model Evaluation Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "948a00c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare predictions for visualization\n",
    "top_3 = ['Random Forest', 'XGBoost', 'Gradient Boosting']\n",
    "preds, probs = {}, {}\n",
    "\n",
    "for name in top_3:\n",
    "    model, _, scale = all_models[name]\n",
    "    Xtr, Xv = (X_train_scaled, X_val_scaled) if scale else (X_train, X_val)\n",
    "    model.fit(Xtr, y_train)\n",
    "    preds[name] = model.predict(Xv)\n",
    "    probs[name] = model.predict_proba(Xv)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7634d83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrices\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "for ax, name in zip(axes, top_3):\n",
    "    cm = confusion_matrix(y_val, preds[name])\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
    "                xticklabels=['Died', 'Survived'], yticklabels=['Died', 'Survived'])\n",
    "    ax.set_title(name)\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('Actual')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/confusion_matrix.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "500c26a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curves\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "for name in top_3:\n",
    "    fpr, tpr, _ = roc_curve(y_val, probs[name])\n",
    "    auc = roc_auc_score(y_val, probs[name])\n",
    "    ax.plot(fpr, tpr, label=f'{name} (AUC={auc:.3f})')\n",
    "ax.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC Curves')\n",
    "ax.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/roc_curve.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63e5631",
   "metadata": {},
   "source": [
    "Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e3b6a46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 Features:\n",
      "       Feature  Average\n",
      "      Title_Mr 1.000000\n",
      "   Sex_encoded 0.562941\n",
      "        Pclass 0.297074\n",
      "          Fare 0.289457\n",
      "  Deck_Unknown 0.241130\n",
      "           Age 0.227870\n",
      "    FamilySize 0.174610\n",
      "    Title_Rare 0.172234\n",
      "     Title_Mrs 0.135595\n",
      "    Title_Miss 0.133756\n",
      "        Deck_E 0.103180\n",
      "        Deck_D 0.102509\n",
      "         SibSp 0.097624\n",
      "Fare_Very_High 0.091744\n",
      "    Embarked_S 0.084625\n"
     ]
    }
   ],
   "source": [
    "importance = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'RF': rf_tuned.feature_importances_,\n",
    "    'XGB': xgb_tuned.feature_importances_,\n",
    "    'GB': gb_tuned.feature_importances_\n",
    "})\n",
    "\n",
    "# Normalize each column\n",
    "for col in ['RF', 'XGB', 'GB']:\n",
    "    importance[col] = importance[col] / importance[col].max()\n",
    "\n",
    "importance['Average'] = importance[['RF', 'XGB', 'GB']].mean(axis=1)\n",
    "importance = importance.sort_values('Average', ascending=False)\n",
    "\n",
    "print(\"Top 15 Features:\")\n",
    "print(importance[['Feature', 'Average']].head(15).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f6637f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_feat = importance.head(15)\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "x = np.arange(len(top_feat))\n",
    "width = 0.25\n",
    "\n",
    "ax.barh(x - width, top_feat['RF'], width, label='Random Forest')\n",
    "ax.barh(x, top_feat['XGB'], width, label='XGBoost')\n",
    "ax.barh(x + width, top_feat['GB'], width, label='Gradient Boosting')\n",
    "\n",
    "ax.set_yticks(x)\n",
    "ax.set_yticklabels(top_feat['Feature'])\n",
    "ax.set_xlabel('Normalized Importance')\n",
    "ax.set_title('Top 15 Feature Importance')\n",
    "ax.legend()\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/feature_importance.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dce7384",
   "metadata": {},
   "source": [
    "Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0eeb62a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retraining Hard Voting (3) on full training data...\n",
      "Generated 418 predictions\n",
      "Predicted survival rate: 35.17%\n",
      "Training survival rate:  38.38%\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nRetraining {best_name} on full training data...\")\n",
    "\n",
    "if needs_scaling:\n",
    "    scaler_full = StandardScaler()\n",
    "    X_full = scaler_full.fit_transform(X)\n",
    "    best_model.fit(X_full, y)\n",
    "    X_test_pred = scaler_full.transform(X_test_final)\n",
    "else:\n",
    "    best_model.fit(X, y)\n",
    "    X_test_pred = X_test_final\n",
    "\n",
    "predictions = best_model.predict(X_test_pred)\n",
    "print(f\"Generated {len(predictions)} predictions\")\n",
    "print(f\"Predicted survival rate: {predictions.mean():.2%}\")\n",
    "print(f\"Training survival rate:  {y.mean():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1a821a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submission saved!\n",
      "   PassengerId  Survived\n",
      "0          892         0\n",
      "1          893         0\n",
      "2          894         0\n",
      "3          895         0\n",
      "4          896         1\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_ids['PassengerId'],\n",
    "    'Survived': predictions\n",
    "})\n",
    "submission.to_csv('../submissions/submission.csv', index=False)\n",
    "print(\"\\nSubmission saved!\")\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a1ecb0",
   "metadata": {},
   "source": [
    "Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bb28308b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All models saved!\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(lr_tuned, '../models/logistic_regression.pkl')\n",
    "joblib.dump(rf_tuned, '../models/random_forest.pkl')\n",
    "joblib.dump(xgb_tuned, '../models/xgboost.pkl')\n",
    "joblib.dump(knn_tuned, '../models/knn.pkl')\n",
    "joblib.dump(gb_tuned, '../models/gradient_boosting.pkl')\n",
    "joblib.dump(best_model, '../models/best_model.pkl')\n",
    "joblib.dump(scaler, '../models/scaler.pkl')\n",
    "print(\"All models saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5352aab5",
   "metadata": {},
   "source": [
    "Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fe5fdbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MODELING COMPLETE\n",
      "======================================================================\n",
      "\n",
      "Baseline vs Tuned:\n",
      "  Logistic Regression   : 0.8132 -> 0.8231 (+0.0098)\n",
      "  Random Forest         : 0.8132 -> 0.8343 (+0.0211)\n",
      "  XGBoost               : 0.8132 -> 0.8371 (+0.0239)\n",
      "\n",
      "Best Model: Hard Voting (3)\n",
      "CV Accuracy: 0.8470\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"MODELING COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nBaseline vs Tuned:\")\n",
    "for name in baseline:\n",
    "    base = baseline[name]\n",
    "    tuned = all_models[name][1]\n",
    "    print(f\"  {name:22}: {base:.4f} -> {tuned:.4f} (+{tuned-base:.4f})\")\n",
    "\n",
    "print(f\"\\nBest Model: {best_name}\")\n",
    "print(f\"CV Accuracy: {best_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venc",
   "language": "python",
   "name": "venc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
