{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f637bb5",
   "metadata": {},
   "source": [
    "Data Processing\n",
    "\n",
    "Objective:\n",
    "Clean and prepare the Titanic Dataset for feature engineering and modeling\n",
    "\n",
    "Tasks:\n",
    "1. Load raw data\n",
    "2. Handle missing values\n",
    "3. Encode categorical variables\n",
    "4. Validate data quality \n",
    "5. Save cleaned dataset for next phase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a173fd0a",
   "metadata": {},
   "source": [
    "Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55a62364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799666ca",
   "metadata": {},
   "source": [
    "Set display options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e85d572",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a149ef0",
   "metadata": {},
   "source": [
    "Load Raw datasets\n",
    "We start fresh from the raw data. Kepps the notebook self-contained and reproducible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c7a4016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (891, 12)\n",
      "Test set: (418, 11)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('../data/raw/train.csv')\n",
    "test_df = pd.read_csv('../data/raw/test.csv')\n",
    "\n",
    "# Store PassengerId for later \n",
    "test_passenger_ids = test_df['PassengerId'].copy()\n",
    "\n",
    "print(f\"Training set: {train_df.shape}\")\n",
    "print(f\"Test set: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5d746d",
   "metadata": {},
   "source": [
    "Check for missing values before we start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9468be2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "MISSING VALUES - TRAINING SET\n",
      "==================================================\n",
      "          Missing Count  Missing %\n",
      "Age                 177      19.87\n",
      "Cabin               687      77.10\n",
      "Embarked              2       0.22\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"MISSING VALUES - TRAINING SET\")\n",
    "print(\"=\" * 50)\n",
    "missing_train = train_df.isnull().sum()\n",
    "missing_pct = (missing_train / len(train_df) * 100).round(2)\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Missing Count': missing_train,\n",
    "    'Missing %': missing_pct\n",
    "})\n",
    "print(missing_summary[missing_summary['Missing Count'] > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5011ba49",
   "metadata": {},
   "source": [
    "Handling Missing Values\n",
    "\n",
    "Based on EDA findings:\n",
    "Age: ~20% missing -> Impute using median by Pclass and Sex\n",
    "Cabin: ~ 77% missing -> Extract deck letter, fill rest with 'Unknown'\n",
    "Embarked: 2 missing values -> Fill with mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0c2f0b",
   "metadata": {},
   "source": [
    "Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5faf35ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with missing Embarked:\n",
      "     PassengerId  Survived  Pclass                                       Name  \\\n",
      "61            62         1       1                        Icard, Miss. Amelie   \n",
      "829          830         1       1  Stone, Mrs. George Nelson (Martha Evelyn)   \n",
      "\n",
      "        Sex   Age  SibSp  Parch  Ticket  Fare Cabin Embarked  \n",
      "61   female  38.0      0      0  113572  80.0   B28      NaN  \n",
      "829  female  62.0      0      0  113572  80.0   B28      NaN  \n"
     ]
    }
   ],
   "source": [
    "print(\"Rows with missing Embarked:\")\n",
    "print(train_df[train_df['Embarked'].isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e8ada5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common embarkation port: S\n",
      "\n",
      "Embarked distribution:\n",
      "Embarked\n",
      "S    644\n",
      "C    168\n",
      "Q     77\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Find the mode for Embarked\n",
    "embarked_mode = train_df['Embarked'].mode()[0]\n",
    "print(f\"Most common embarkation port: {embarked_mode}\")\n",
    "print(f\"\\nEmbarked distribution:\")\n",
    "print(train_df['Embarked'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1117f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embarked missing values after imputation: 0\n"
     ]
    }
   ],
   "source": [
    "# Fill missing Embarked with mode\n",
    "train_df['Embarked'] = train_df['Embarked'].fillna(embarked_mode)\n",
    "test_df['Embarked'] = test_df['Embarked'].fillna(embarked_mode)\n",
    "\n",
    "print(f\"Embarked missing values after imputation: {train_df['Embarked'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e970847f",
   "metadata": {},
   "source": [
    "Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8be87a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median ages by Pclass and Sex:\n",
      "Pclass  Sex   \n",
      "1       female    35.0\n",
      "        male      40.0\n",
      "2       female    28.0\n",
      "        male      30.0\n",
      "3       female    21.5\n",
      "        male      25.0\n",
      "Name: Age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate median age by Pclass and Sex\n",
    "age_medians = train_df.groupby(['Pclass', 'Sex'])['Age'].median()\n",
    "print(\"Median ages by Pclass and Sex:\")\n",
    "print(age_medians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a46a2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age missing values after imputation:\n",
      "  Train: 0\n",
      "  Test: 0\n"
     ]
    }
   ],
   "source": [
    "def impute_age(df, age_medians):\n",
    "    \"\"\"\n",
    "    Impute missing ages using median by Pclass and Sex.\n",
    "    Returns a copy with imputed values.\n",
    "\n",
    "    Args:\n",
    "        df (_type_): _description_\n",
    "        age_medians (_type_): _description_\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    for (pclass, sex), median_age in age_medians.items():\n",
    "        mask = (df['Age'].isnull()) & (df['Pclass'] == pclass) & (df['Sex'] == sex)\n",
    "        df.loc[mask, 'Age'] = median_age\n",
    "    \n",
    "    \n",
    "    overall_median = df['Age'].median()\n",
    "    df['Age'] = df['Age'].fillna(overall_median)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "train_df = impute_age(train_df, age_medians)\n",
    "test_df = impute_age(test_df, age_medians)\n",
    "\n",
    "print(f\"Age missing values after imputation:\")\n",
    "print(f\"  Train: {train_df['Age'].isnull().sum()}\")\n",
    "print(f\"  Test: {test_df['Age'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f33cf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization age distribution before and after\n",
    "original_train = pd.read_csv('../data/raw/train.csv')\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].hist(original_train['Age'].dropna(), bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_title('Age Distribution (Before Imputation)')\n",
    "axes[0].set_xlabel('Age')\n",
    "axes[0].set_ylabel('Count')\n",
    "\n",
    "axes[1].hist(train_df['Age'], bins=30, edgecolor='black', alpha=0.7, color='green')\n",
    "axes[1].set_title('Age Distribution (After Imputation)')\n",
    "axes[1].set_xlabel('Age')\n",
    "axes[1].set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/age_imputation_comparison.png')\n",
    "plt.close()\n",
    "\n",
    "del original_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23e74f3",
   "metadata": {},
   "source": [
    "Cabin - Extract Deck Information\n",
    "\n",
    "While 77% of Cabin data is missing, we can still extract useful information:\n",
    "The deck letter (A, B, C, etc.) indicates location on ship\n",
    "Having cabin info at all may indicate higher status passengers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90c9c4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deck distribution (Training):\n",
      "Deck\n",
      "Unknown    687\n",
      "C           59\n",
      "B           47\n",
      "D           33\n",
      "E           32\n",
      "A           15\n",
      "F           13\n",
      "G            4\n",
      "T            1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def extract_deck(cabin):\n",
    "    \"\"\"\n",
    "    Extract deck letter from cabin number.\n",
    "    Returns 'Unknown' if cabin is missing.\n",
    "\n",
    "    Args:\n",
    "        cabin (_type_): _description_\n",
    "    \"\"\"\n",
    "    \n",
    "    if pd.isnull(cabin):\n",
    "        return 'Unknown'\n",
    "    return cabin[0]\n",
    "\n",
    "\n",
    "train_df['Deck'] = train_df['Cabin'].apply(extract_deck)\n",
    "test_df['Deck'] = test_df['Cabin'].apply(extract_deck)\n",
    "\n",
    "print(\"Deck distribution (Training):\")\n",
    "print(train_df['Deck'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "685a3c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Survival rate by deck:\n",
      "         Survival Rate  Count\n",
      "Deck                         \n",
      "D             0.757576     33\n",
      "E             0.750000     32\n",
      "B             0.744681     47\n",
      "F             0.615385     13\n",
      "C             0.593220     59\n",
      "G             0.500000      4\n",
      "A             0.466667     15\n",
      "Unknown       0.299854    687\n",
      "T             0.000000      1\n"
     ]
    }
   ],
   "source": [
    "# Check survival rate by deck\n",
    "deck_survival = train_df.groupby('Deck')['Survived'].agg(['mean', 'count'])\n",
    "deck_survival.columns = ['Survival Rate', 'Count']\n",
    "deck_survival = deck_survival.sort_values('Survival Rate', ascending=False)\n",
    "print(\"\\nSurvival rate by deck:\")\n",
    "print(deck_survival)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87009339",
   "metadata": {},
   "source": [
    "Fare - Check for missing values in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bb2b6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Fare in test set: 1\n",
      "Missing Fare after imputation: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Missing Fare in test set: {test_df['Fare'].isnull().sum()}\")\n",
    "\n",
    "if test_df['Fare'].isnull().sum() > 0:\n",
    "    # Impute with median fare for that Pclass\n",
    "    for pclass in test_df['Pclass'].unique():\n",
    "        median_fare = train_df[train_df['Pclass'] == pclass]['Fare'].median()\n",
    "        mask = (test_df['Fare'].isnull()) & (test_df['Pclass'] == pclass)\n",
    "        test_df.loc[mask, 'Fare'] = median_fare\n",
    "    print(f\"Missing Fare after imputation: {test_df['Fare'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb404c6",
   "metadata": {},
   "source": [
    "Encode Categorical Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ea390ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex encoding:\n",
      "      Sex  Sex_encoded\n",
      "0    male            0\n",
      "1  female            1\n"
     ]
    }
   ],
   "source": [
    "# Sex : Binary encoding (female = 1, male = 0)\n",
    "#Makes interpretation easier: positive coefficient = higher survival for females\n",
    "\n",
    "train_df['Sex_encoded'] = train_df['Sex'].map({'female': 1, 'male': 0})\n",
    "test_df['Sex_encoded'] = test_df['Sex'].map({'female': 1, 'male': 0})\n",
    "\n",
    "print(\"Sex encoding:\")\n",
    "print(train_df[['Sex', 'Sex_encoded']].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "906866b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embarked one-hot columns added:\n",
      "['Embarked_C', 'Embarked_Q', 'Embarked_S']\n"
     ]
    }
   ],
   "source": [
    "# Embarked: One-hot encoding\n",
    "embarked_dummies_train = pd.get_dummies(train_df['Embarked'], prefix='Embarked')\n",
    "embarked_dummies_test = pd.get_dummies(test_df['Embarked'], prefix='Embarked')\n",
    "\n",
    "train_df = pd.concat([train_df, embarked_dummies_train], axis=1)\n",
    "test_df = pd.concat([test_df, embarked_dummies_test], axis=1)\n",
    "\n",
    "print(\"Embarked one-hot columns added:\")\n",
    "print([col for col in train_df.columns if 'Embarked_' in col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bef5fc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deck columns added: 9\n"
     ]
    }
   ],
   "source": [
    "# Deck: One-hot encoding\n",
    "deck_dummies_train = pd.get_dummies(train_df['Deck'], prefix='Deck')\n",
    "deck_dummies_test = pd.get_dummies(test_df['Deck'], prefix='Deck')\n",
    "\n",
    "# Ensure both have same columns (test might be missing some decks)\n",
    "for col in deck_dummies_train.columns:\n",
    "    if col not in deck_dummies_test.columns:\n",
    "        deck_dummies_test[col] = 0\n",
    "\n",
    "# Reorder test columns to match train\n",
    "deck_dummies_test = deck_dummies_test[deck_dummies_train.columns]\n",
    "\n",
    "train_df = pd.concat([train_df, deck_dummies_train], axis=1)\n",
    "test_df = pd.concat([test_df, deck_dummies_test], axis=1)\n",
    "\n",
    "print(f\"Deck columns added: {len(deck_dummies_train.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e514b84b",
   "metadata": {},
   "source": [
    "Drop Redunant and Unused Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "abc98b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped columns: ['Sex', 'Embarked', 'Cabin', 'Deck', 'PassengerId', 'Ticket']\n",
      "\n",
      "Remaining columns: ['Survived', 'Pclass', 'Name', 'Age', 'SibSp', 'Parch', 'Fare', 'Sex_encoded', 'Embarked_C', 'Embarked_Q', 'Embarked_S', 'Deck_A', 'Deck_B', 'Deck_C', 'Deck_D', 'Deck_E', 'Deck_F', 'Deck_G', 'Deck_T', 'Deck_Unknown']\n"
     ]
    }
   ],
   "source": [
    "# Columns to drop after encoding\n",
    "columns_to_drop = [\n",
    "    'Sex',        # Replaced by Sex_encoded\n",
    "    'Embarked',   # Replaced by Embarked_* one-hot columns\n",
    "    'Cabin',      # Replaced by Deck_* one-hot columns\n",
    "    'Deck',       # Replaced by Deck_* one-hot columns\n",
    "    'PassengerId',# Just an identifier\n",
    "    'Ticket',     # Messy, not using for now\n",
    "]\n",
    "\n",
    "\n",
    "train_df = train_df.drop(columns=columns_to_drop)\n",
    "test_df = test_df.drop(columns=columns_to_drop)\n",
    "\n",
    "print(f\"Dropped columns: {columns_to_drop}\")\n",
    "print(f\"\\nRemaining columns: {list(train_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8384615e",
   "metadata": {},
   "source": [
    "Data Quality Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4cc28cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "FINAL MISSING VALUE CHECK\n",
      "==================================================\n",
      "\n",
      "Training set:\n",
      "No missing values!\n",
      "\n",
      "Test set:\n",
      "No missing values!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"FINAL MISSING VALUE CHECK\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\nTraining set:\")\n",
    "train_missing = train_df.isnull().sum()\n",
    "if train_missing.sum() > 0:\n",
    "    print(train_missing[train_missing > 0])\n",
    "else:\n",
    "    print(\"No missing values!\")\n",
    "\n",
    "print(\"\\nTest set:\")\n",
    "test_missing = test_df.isnull().sum()\n",
    "if test_missing.sum() > 0:\n",
    "    print(test_missing[test_missing > 0])\n",
    "else:\n",
    "    print(\"No missing values!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a04e642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data types (Training):\n",
      "Survived          int64\n",
      "Pclass            int64\n",
      "Name             object\n",
      "Age             float64\n",
      "SibSp             int64\n",
      "Parch             int64\n",
      "Fare            float64\n",
      "Sex_encoded       int64\n",
      "Embarked_C         bool\n",
      "Embarked_Q         bool\n",
      "Embarked_S         bool\n",
      "Deck_A             bool\n",
      "Deck_B             bool\n",
      "Deck_C             bool\n",
      "Deck_D             bool\n",
      "Deck_E             bool\n",
      "Deck_F             bool\n",
      "Deck_G             bool\n",
      "Deck_T             bool\n",
      "Deck_Unknown       bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check data types\n",
    "print(\"\\nData types (Training):\")\n",
    "print(train_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f262e2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned dataset preview:\n",
      "   Survived  Pclass                                               Name   Age  \\\n",
      "0         0       3                            Braund, Mr. Owen Harris  22.0   \n",
      "1         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...  38.0   \n",
      "2         1       3                             Heikkinen, Miss. Laina  26.0   \n",
      "3         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  35.0   \n",
      "4         0       3                           Allen, Mr. William Henry  35.0   \n",
      "\n",
      "   SibSp  Parch     Fare  Sex_encoded  Embarked_C  Embarked_Q  Embarked_S  \\\n",
      "0      1      0   7.2500            0       False       False        True   \n",
      "1      1      0  71.2833            1        True       False       False   \n",
      "2      0      0   7.9250            1       False       False        True   \n",
      "3      1      0  53.1000            1       False       False        True   \n",
      "4      0      0   8.0500            0       False       False        True   \n",
      "\n",
      "   Deck_A  Deck_B  Deck_C  Deck_D  Deck_E  Deck_F  Deck_G  Deck_T  \\\n",
      "0   False   False   False   False   False   False   False   False   \n",
      "1   False   False    True   False   False   False   False   False   \n",
      "2   False   False   False   False   False   False   False   False   \n",
      "3   False   False    True   False   False   False   False   False   \n",
      "4   False   False   False   False   False   False   False   False   \n",
      "\n",
      "   Deck_Unknown  \n",
      "0          True  \n",
      "1         False  \n",
      "2          True  \n",
      "3         False  \n",
      "4          True  \n"
     ]
    }
   ],
   "source": [
    "# Preview the cleaned data\n",
    "print(\"\\nCleaned dataset preview:\")\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a6667f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total columns: 20\n",
      "\n",
      "Column list:\n",
      "   1. Survived\n",
      "   2. Pclass\n",
      "   3. Name\n",
      "   4. Age\n",
      "   5. SibSp\n",
      "   6. Parch\n",
      "   7. Fare\n",
      "   8. Sex_encoded\n",
      "   9. Embarked_C\n",
      "  10. Embarked_Q\n",
      "  11. Embarked_S\n",
      "  12. Deck_A\n",
      "  13. Deck_B\n",
      "  14. Deck_C\n",
      "  15. Deck_D\n",
      "  16. Deck_E\n",
      "  17. Deck_F\n",
      "  18. Deck_G\n",
      "  19. Deck_T\n",
      "  20. Deck_Unknown\n"
     ]
    }
   ],
   "source": [
    "# List all columns now available\n",
    "print(f\"\\nTotal columns: {len(train_df.columns)}\")\n",
    "print(\"\\nColumn list:\")\n",
    "for i, col in enumerate(train_df.columns, 1):\n",
    "    print(f\"  {i:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c064ed",
   "metadata": {},
   "source": [
    "Save Processed datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "021b71e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved preprocessed data:\n",
      "  - ../data/processed/train_preprocessed.csv\n",
      "  - ../data/processed/test_preprocessed.csv\n",
      "  - ../data/processed/test_passenger_ids.csv\n"
     ]
    }
   ],
   "source": [
    "# Save preprocessed datasets\n",
    "train_df.to_csv('../data/processed/train_preprocessed.csv', index=False)\n",
    "test_df.to_csv('../data/processed/test_preprocessed.csv', index=False)\n",
    "\n",
    "# Also save the test passenger IDs separately (needed for submission)\n",
    "test_passenger_ids.to_csv('../data/processed/test_passenger_ids.csv', index=False)\n",
    "\n",
    "print(\"Saved preprocessed data:\")\n",
    "print(\"  - ../data/processed/train_preprocessed.csv\")\n",
    "print(\"  - ../data/processed/test_preprocessed.csv\")\n",
    "print(\"  - ../data/processed/test_passenger_ids.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc04eabe",
   "metadata": {},
   "source": [
    "Summary\n",
    "\n",
    "What we accomplished:\n",
    "1. **Embarked**: Filled 2 missing values with mode ('S' - Southampton)\n",
    "2. **Age**: Imputed ~20% missing values using median by Pclass and Sex\n",
    "3. **Cabin**: Extracted Deck information, labeled missing as 'Unknown'\n",
    "4. **Fare**: Checked and imputed any missing values in test set\n",
    "5. **Encoded**: Sex (binary), Embarked (one-hot), Deck (one-hot)\n",
    "\n",
    "Next steps (03_feature_engineering.ipynb):\n",
    "Extract titles from names (Mr, Mrs, Miss, etc.)\n",
    "Create family size feature (SibSp + Parch + 1)\n",
    "Create 'IsAlone' binary feature\n",
    "Bin Age and Fare into categories\n",
    "Create interaction features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
